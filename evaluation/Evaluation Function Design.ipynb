{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f763e7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tompickard/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jiwer\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Used to convert numbers to words, e.g. 8 o'clock -> eight o'clock, 1944 -> nineteen forty four\n",
    "import inflect\n",
    "# Inflect is more flexible, but doesn't create ordinals as words - use num2words for that\n",
    "from num2words import num2words\n",
    "\n",
    "import pyperclip as ppc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6850a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tompickard/MiniProject/Legasee-Oral-History\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/tompickard/MiniProject/Legasee-Oral-History/'\n",
    "\n",
    "from measures import compute_measures\n",
    "\n",
    "from evaluation import kword_prep, score_name\n",
    "\n",
    "from evaluation import transform_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b86fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0b6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSPATH = os.path.expanduser(\"~\")+'/H_Drive/srv/studat/cdt/team2'\n",
    "TEST_TRAIN = 'test'\n",
    "M_FOLDER = 'final_output_001'\n",
    "\n",
    "SUB_FOLDERS = False\n",
    "\n",
    "SHARED_WORD_WEIGHT = 3\n",
    "KEY_WEIGHT = 7\n",
    "TRANSFORM = transform_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff3ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ecfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata from CSV\n",
    "\n",
    "META_PATH = os.path.expanduser(\"~\")+SYSPATH+'/data/legasee/metadata/'\n",
    "\n",
    "meta_df = pd.read_csv(META_PATH+'master_metadata.csv', converters={'Priority Words': eval, 'Name Words' : eval})\n",
    "\n",
    "# Remove Test items\n",
    "train_meta = meta_df[~pd.Series(meta_df.Allocation == \"Test\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f82029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared keywords (from training data)\n",
    "\n",
    "all_words = [x for subl in train_meta['Priority Words'] for w in subl for x in re.split('[\\s/]',w)]\n",
    "all_words_clean = kword_prep(all_words,transform_baseline)\n",
    "\n",
    "\n",
    "wdict = {w : SHARED_WORD_WEIGHT for w in all_words_clean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ccaca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa14f588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Keywords</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Unweighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Weighted (own keywords)</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Weighted (own + shared keywords)</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Keywords (own) only</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Incidence</th>\n",
       "      <th>deletions</th>\n",
       "      <th>hits</th>\n",
       "      <th>insertions</th>\n",
       "      <th>mer</th>\n",
       "      <th>substitutions</th>\n",
       "      <th>wer</th>\n",
       "      <th>wip</th>\n",
       "      <th>wer</th>\n",
       "      <th>mer</th>\n",
       "      <th>...</th>\n",
       "      <th>substitutions</th>\n",
       "      <th>deletions</th>\n",
       "      <th>insertions</th>\n",
       "      <th>wer</th>\n",
       "      <th>mer</th>\n",
       "      <th>wip</th>\n",
       "      <th>hits</th>\n",
       "      <th>substitutions</th>\n",
       "      <th>deletions</th>\n",
       "      <th>insertions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gordon Hooton</th>\n",
       "      <td>[(east, 2), (home, 16), (description, 0), (cha...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>489.0</td>\n",
       "      <td>0.192862</td>\n",
       "      <td>0.745266</td>\n",
       "      <td>0.178778</td>\n",
       "      <td>0.167143</td>\n",
       "      <td>...</td>\n",
       "      <td>589.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irene Bellamy</th>\n",
       "      <td>[(dockyard, 0), (initial, 0), (childhood, 0), ...</td>\n",
       "      <td>234.0</td>\n",
       "      <td>7090.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.107165</td>\n",
       "      <td>429.0</td>\n",
       "      <td>0.109764</td>\n",
       "      <td>0.841274</td>\n",
       "      <td>0.111423</td>\n",
       "      <td>0.109205</td>\n",
       "      <td>...</td>\n",
       "      <td>673.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.790204</td>\n",
       "      <td>220.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joan Field</th>\n",
       "      <td>[(initial, 0), (description, 0), (field, 1), (...</td>\n",
       "      <td>208.0</td>\n",
       "      <td>5603.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>0.191953</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0.208131</td>\n",
       "      <td>0.729867</td>\n",
       "      <td>0.220416</td>\n",
       "      <td>0.204808</td>\n",
       "      <td>...</td>\n",
       "      <td>872.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>0.469611</td>\n",
       "      <td>75.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joe Pitcher</th>\n",
       "      <td>[(initial, 0), (chatham, 7), (training, 0), (g...</td>\n",
       "      <td>224.0</td>\n",
       "      <td>5218.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.210709</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.225587</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.220319</td>\n",
       "      <td>0.207312</td>\n",
       "      <td>...</td>\n",
       "      <td>997.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>106.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Woodward</th>\n",
       "      <td>[(leave, 4), (acoustic, 1), (description, 0), ...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.221524</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.260840</td>\n",
       "      <td>0.728343</td>\n",
       "      <td>0.232790</td>\n",
       "      <td>0.203136</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.102804</td>\n",
       "      <td>0.812555</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodney Newham</th>\n",
       "      <td>[(dockyard, 11), (casualty, 0), (repair, 0), (...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.165096</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.174991</td>\n",
       "      <td>0.762530</td>\n",
       "      <td>0.157328</td>\n",
       "      <td>0.149654</td>\n",
       "      <td>...</td>\n",
       "      <td>266.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.909474</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vic Ould</th>\n",
       "      <td>[(dockyard, 0), (initial, 0), (carron, 2), (ch...</td>\n",
       "      <td>322.0</td>\n",
       "      <td>11035.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.168112</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.179131</td>\n",
       "      <td>0.755745</td>\n",
       "      <td>0.177066</td>\n",
       "      <td>0.167771</td>\n",
       "      <td>...</td>\n",
       "      <td>1532.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.165789</td>\n",
       "      <td>0.730510</td>\n",
       "      <td>317.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Keywords Unweighted  \\\n",
       "                                                       Incidence  deletions   \n",
       "Gordon Hooton  [(east, 2), (home, 16), (description, 0), (cha...      148.0   \n",
       "Irene Bellamy  [(dockyard, 0), (initial, 0), (childhood, 0), ...      234.0   \n",
       "Joan Field     [(initial, 0), (description, 0), (field, 1), (...      208.0   \n",
       "Joe Pitcher    [(initial, 0), (chatham, 7), (training, 0), (g...      224.0   \n",
       "John Woodward  [(leave, 4), (acoustic, 1), (description, 0), ...       71.0   \n",
       "Rodney Newham  [(dockyard, 11), (casualty, 0), (repair, 0), (...       89.0   \n",
       "Vic Ould       [(dockyard, 0), (initial, 0), (carron, 2), (ch...      322.0   \n",
       "\n",
       "                                                                               \\\n",
       "                  hits insertions       mer substitutions       wer       wip   \n",
       "Gordon Hooton   4911.0      433.0  0.178900         489.0  0.192862  0.745266   \n",
       "Irene Bellamy   7090.0      188.0  0.107165         429.0  0.109764  0.841274   \n",
       "Joan Field      5603.0      539.0  0.191953         584.0  0.208131  0.729867   \n",
       "Joe Pitcher     5218.0      436.0  0.210709         733.0  0.225587  0.690358   \n",
       "John Woodward   2727.0      528.0  0.221524         177.0  0.260840  0.728343   \n",
       "Rodney Newham   2392.0      162.0  0.165096         222.0  0.174991  0.762530   \n",
       "Vic Ould       11035.0      816.0  0.168112        1092.0  0.179131  0.755745   \n",
       "\n",
       "              Weighted (own keywords)            ...  \\\n",
       "                                  wer       mer  ...   \n",
       "Gordon Hooton                0.178778  0.167143  ...   \n",
       "Irene Bellamy                0.111423  0.109205  ...   \n",
       "Joan Field                   0.220416  0.204808  ...   \n",
       "Joe Pitcher                  0.220319  0.207312  ...   \n",
       "John Woodward                0.232790  0.203136  ...   \n",
       "Rodney Newham                0.157328  0.149654  ...   \n",
       "Vic Ould                     0.177066  0.167771  ...   \n",
       "\n",
       "              Weighted (own + shared keywords)                       \\\n",
       "                                 substitutions deletions insertions   \n",
       "Gordon Hooton                            589.0     172.0      433.0   \n",
       "Irene Bellamy                            673.0     298.0      188.0   \n",
       "Joan Field                               872.0     258.0      539.0   \n",
       "Joe Pitcher                              997.0     242.0      436.0   \n",
       "John Woodward                            259.0      81.0      528.0   \n",
       "Rodney Newham                            266.0     109.0      162.0   \n",
       "Vic Ould                                1532.0     472.0      816.0   \n",
       "\n",
       "              Keywords (own) only                                           \\\n",
       "                              wer       mer       wip   hits substitutions   \n",
       "Gordon Hooton            0.062500  0.062500  0.894886  105.0           5.0   \n",
       "Irene Bellamy            0.120000  0.120000  0.790204  220.0          25.0   \n",
       "Joan Field               0.336283  0.336283  0.469611   75.0          31.0   \n",
       "Joe Pitcher              0.178295  0.178295  0.675200  106.0          23.0   \n",
       "John Woodward            0.102804  0.102804  0.812555   96.0          10.0   \n",
       "Rodney Newham            0.052632  0.052632  0.909474   72.0           3.0   \n",
       "Vic Ould                 0.165789  0.165789  0.730510  317.0          45.0   \n",
       "\n",
       "                                    \n",
       "              deletions insertions  \n",
       "Gordon Hooton       2.0        0.0  \n",
       "Irene Bellamy       5.0        0.0  \n",
       "Joan Field          7.0        0.0  \n",
       "Joe Pitcher         0.0        0.0  \n",
       "John Woodward       1.0        0.0  \n",
       "Rodney Newham       1.0        0.0  \n",
       "Vic Ould           18.0        0.0  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_started = 0\n",
    "\n",
    "if SUB_FOLDERS:\n",
    "    for _fn in os.scandir(SYSPATH+'/system_outputs/'+M_FOLDER):\n",
    "        # Only want to process folders. Ignore any starting with .\n",
    "        if _fn.is_dir() and not _fn.name.startswith('.'):\n",
    "            name_df, _, _ = score_name(_fn.name,\n",
    "                   meta_df,\n",
    "                   SYSPATH,\n",
    "                   M_FOLDER,\n",
    "                   TEST_TRAIN,\n",
    "                   KEY_WEIGHT,\n",
    "                   wdict,\n",
    "                   TRANSFORM,\n",
    "                   in_folders = SUB_FOLDERS,\n",
    "                  )\n",
    "\n",
    "            if type(name_df) != type(None):\n",
    "                if _started:\n",
    "                    scores_df = scores_df.append(name_df)\n",
    "\n",
    "                else:\n",
    "                    _started = 1\n",
    "                    scores_df = name_df.copy()\n",
    "                    \n",
    "else:\n",
    "    for _fn in os.scandir(SYSPATH+'/system_outputs/'+M_FOLDER):\n",
    "        # Get names from files\n",
    "        if _fn.is_file() and not _fn.name.startswith('.') and _fn.name[-4:] == '.txt':\n",
    "            _name = _fn.name[:-4]\n",
    "            name_df, _, _ = score_name(_name,\n",
    "                   meta_df,\n",
    "                   SYSPATH,\n",
    "                   M_FOLDER,\n",
    "                   TEST_TRAIN,\n",
    "                   KEY_WEIGHT,\n",
    "                   wdict,\n",
    "                   TRANSFORM,\n",
    "                   in_folders = SUB_FOLDERS,\n",
    "                  )\n",
    "            \n",
    "            if type(name_df) != type(None):\n",
    "                if _started:\n",
    "                    scores_df = scores_df.append(name_df)\n",
    "\n",
    "                else:\n",
    "                    _started = 1\n",
    "                    scores_df = name_df.copy()\n",
    "                    \n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b77998-d131-4309-8c41-3d74b7a3f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(SYSPATH+'/system_outputs/'+M_FOLDER+'_'+'evaluation_scores.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fd6cb-24a0-41f0-b2dc-cc63f94fe9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29514b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = scores_df['Unweighted','wer'].mean()\n",
    "wwer = scores_df['Weighted (own + shared keywords)','wer'].mean()\n",
    "kwer = scores_df['Keywords (own) only','wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1f1742-971b-4f57-bf5c-4f7daaf90582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER:  0.1930437990349416 \n",
      " WWER:  0.171211773885281 \n",
      " KWER:  0.14547179291906495\n"
     ]
    }
   ],
   "source": [
    "print('WER: ', wer , '\\n', 'WWER: ', wwer, '\\n', 'KWER: ',kwer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

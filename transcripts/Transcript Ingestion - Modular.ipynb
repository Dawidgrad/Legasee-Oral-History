{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4818b49-29f6-4732-b0bf-b9a6d3992462",
   "metadata": {},
   "source": [
    "### Transcript ingestion and standardisation\n",
    "\n",
    "Modularised version of initial code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b1db9-89bb-46c9-9bb2-dbaa8fe11a3f",
   "metadata": {},
   "source": [
    "NB: 3 different document formats present.\n",
    "\n",
    " 1 file (Peter Dunstan.txt) is a .txt. It opens with boilerplate (which seems to be the same as the bulk of the PDF documents), then has timestamped segments (similar to automated Zoom transcripts and the like, though the accuracy suggests it's been done or cleaned up by a human).\n",
    " \n",
    " The other files are all in PDF format.\n",
    " \n",
    " 1 (Frank Wilson Transcript Master.pdf) has professional-looking formatting, with:\n",
    "   - Header (Legasee logo) and footer (copyright info)\n",
    "   - Each section identifying the speaker (Frank or the interviewer)\n",
    "   - No general timestamps, however:\n",
    "   - Some sections marked as \"unintelligible\", with corresponding timeststamps\n",
    "   \n",
    " 4 other files are consistent:\n",
    "   - Front page is copyright info etc.\n",
    "   - Metadata (interviewee name and regiment, date and name of transcriber)\n",
    "   - Tables (from MS Word) with time stamps, text (bold indicating interviewer speaking), highlighted sections marking film breaks\n",
    "   - Footers (Legasee information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db73bea-0688-4845-b3fa-c039b83c4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c02037b2-76f1-4134-95e3-729d77f00280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tompickard/MiniProject/Legasee-Oral-History\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/tompickard/MiniProject/Legasee-Oral-History/'\n",
    "\n",
    "from transcript_ingestion import page_to_ts, fancy_page_to_ts, text_to_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0ebfe",
   "metadata": {},
   "source": [
    "Check for existence of input and output folders (and interrupt / create if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34132724",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert path.exists('./raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eaf9101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder ./ingested CREATED.\n"
     ]
    }
   ],
   "source": [
    "if path.exists('./ingested'):\n",
    "    print(\"Output folder ./ingested found.\")\n",
    "    \n",
    "else:\n",
    "    makedirs('./ingested')\n",
    "    print (\"Output folder ./ingested CREATED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e07dd1e9-b82c-4425-ac4d-d498feb61938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081573ac-926d-4a30-b9a7-054f17d33045",
   "metadata": {},
   "source": [
    "Ingest 4 consistent PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d12819-9096-4bd5-bfeb-cd2d80fb91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_standard = ['Baden Singleton', 'Harriet Wright', 'John Roche', 'Mervyn Salter']\n",
    "pdf_standard = ['Ted Rogers']\n",
    "\n",
    "for name in pdf_standard:\n",
    "    \n",
    "    doc = fitz.open('./raw/batch_0/'+name+'.pdf')\n",
    "    \n",
    "    transcripts = []\n",
    "\n",
    "    # Omit first page as it's copyright material / frontispiece\n",
    "    for page in doc.pages(1):\n",
    "        transcripts.extend(page_to_ts(page))\n",
    "        \n",
    "    df = pd.DataFrame(transcripts,columns = [\"Timestamp\", \"Speaker\", \"Transcript\"])\n",
    "    \n",
    "    df.to_csv('./ingested/'+name+'.tsv',\n",
    "              sep = '\\t'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418730b-86ef-4e7e-818f-6b0b51ba1d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c042680a",
   "metadata": {},
   "source": [
    "Ingest one fancy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "566d27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_fancy = ['Frank Wilson']\n",
    "\n",
    "for name in pdf_fancy:\n",
    "    \n",
    "    doc = fitz.open('./raw/'+name+' Transcript Master.pdf')\n",
    "    \n",
    "    transcripts = []\n",
    "\n",
    "    for page in doc.pages():\n",
    "        transcripts.extend(fancy_page_to_ts(page))\n",
    "        \n",
    "    df = pd.DataFrame(transcripts,columns = [\"Timestamp\", \"Speaker\", \"Transcript\"])\n",
    "    \n",
    "    df.to_csv('./ingested/'+name+'.tsv',\n",
    "              sep = '\\t'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70839aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed47734c",
   "metadata": {},
   "source": [
    "Text file.\n",
    "\n",
    "Lines may be:\n",
    " - Boilerplate (everything before the first \"Start of film\")\n",
    " - ** Start of Film X\n",
    " - Timestamp\n",
    " - Content\n",
    " - Blank lines\n",
    " \n",
    "No speaker indicators; approximately alternates, but not consistently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3b0f3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = ['Peter Dunstan']\n",
    "\n",
    "\n",
    "\n",
    "for name in text_list:\n",
    "    \n",
    "    transcript = text_to_ts(name)\n",
    "\n",
    "    df = pd.DataFrame(transcript,columns = [\"Timestamp\", \"Speaker\", \"Transcript\"])\n",
    "    \n",
    "    df.to_csv('./ingested/'+name+'.tsv',\n",
    "              sep = '\\t'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e833ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4325289f",
   "metadata": {},
   "source": [
    "Development / exploration commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f867d944-3945-418d-9f37-77fc0337cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = fitz.open('./raw/Frank Wilson Transcript Master.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44d599a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc.page_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd789509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6513e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page = doc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8713e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = page.get_text(\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c61f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(HTML(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f2b0d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#page_bs = BeautifulSoup(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d0fa41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fancy_page_to_ts(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f12a2a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74d792f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcripts = []\\n\\n# Omit first page as it\\'s copyright material / frontispiece\\nfor page in doc.pages(1):\\n    transcripts.extend(page_to_ts(page))\\n    \\n    df = pd.DataFrame(transcripts,columns = [\"Timestamp\", \"Speaker\", \"Transcript\"])\\n    \\ndf\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "transcripts = []\n",
    "\n",
    "# Omit first page as it's copyright material / frontispiece\n",
    "for page in doc.pages(1):\n",
    "    transcripts.extend(page_to_ts(page))\n",
    "    \n",
    "    df = pd.DataFrame(transcripts,columns = [\"Timestamp\", \"Speaker\", \"Transcript\"])\n",
    "    \n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acbd2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
